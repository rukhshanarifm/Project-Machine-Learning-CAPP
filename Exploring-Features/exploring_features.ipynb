{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pipeline as p\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv(\"../data_consolidation/consolidated_version2.csv\")\n",
    "#df = pd.read_csv(\"C:/Users/Maca/Documents/project_ml/Project-Machine-Learning-CAPP/data_consolidation/consolidated_version2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>bot</th>\n",
       "      <th>description</th>\n",
       "      <th>probe_timestamp</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>protected</th>\n",
       "      <th>verified</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3039154799</td>\n",
       "      <td>human</td>\n",
       "      <td>••TEEN WOLF//SKAM//SHAMELESS••Il mio livello d...</td>\n",
       "      <td>Thu May 16 13:57:12 +0000 2019</td>\n",
       "      <td>Sun Feb 15 14:56:36 +0000 2015</td>\n",
       "      <td>it</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163</td>\n",
       "      <td>407</td>\n",
       "      <td>0</td>\n",
       "      <td>4193</td>\n",
       "      <td>5761</td>\n",
       "      <td>cresci-rtbust-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>390617262</td>\n",
       "      <td>bot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Apr 16 13:51:17 +0000 2019</td>\n",
       "      <td>Fri Oct 14 08:00:55 +0000 2011</td>\n",
       "      <td>it</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>289</td>\n",
       "      <td>401</td>\n",
       "      <td>1</td>\n",
       "      <td>213</td>\n",
       "      <td>3210</td>\n",
       "      <td>cresci-rtbust-2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          id    bot  \\\n",
       "0           0  3039154799  human   \n",
       "1           1   390617262    bot   \n",
       "\n",
       "                                         description  \\\n",
       "0  ••TEEN WOLF//SKAM//SHAMELESS••Il mio livello d...   \n",
       "1                                                NaN   \n",
       "\n",
       "                  probe_timestamp                      created_at lang  \\\n",
       "0  Thu May 16 13:57:12 +0000 2019  Sun Feb 15 14:56:36 +0000 2015   it   \n",
       "1  Tue Apr 16 13:51:17 +0000 2019  Fri Oct 14 08:00:55 +0000 2011   it   \n",
       "\n",
       "  protected  verified  geo_enabled  default_profile  followers_count  \\\n",
       "0     False       0.0          0.0              1.0              163   \n",
       "1     False       0.0          0.0              1.0              289   \n",
       "\n",
       "   friends_count  listed_count  favourites_count  statuses_count  \\\n",
       "0            407             0              4193            5761   \n",
       "1            401             1               213            3210   \n",
       "\n",
       "               source  \n",
       "0  cresci-rtbust-2019  \n",
       "1  cresci-rtbust-2019  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'bot', 'description', 'probe_timestamp',\n",
       "       'created_at', 'lang', 'protected', 'verified', 'geo_enabled',\n",
       "       'default_profile', 'followers_count', 'friends_count', 'listed_count',\n",
       "       'favourites_count', 'statuses_count', 'source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>verified</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>63264.000000</td>\n",
       "      <td>6.326400e+04</td>\n",
       "      <td>55721.000000</td>\n",
       "      <td>56860.000000</td>\n",
       "      <td>56166.000000</td>\n",
       "      <td>6.326400e+04</td>\n",
       "      <td>6.326400e+04</td>\n",
       "      <td>63264.000000</td>\n",
       "      <td>63264.000000</td>\n",
       "      <td>6.326400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20393.214356</td>\n",
       "      <td>7.179809e+17</td>\n",
       "      <td>0.057267</td>\n",
       "      <td>0.155575</td>\n",
       "      <td>0.816704</td>\n",
       "      <td>5.140114e+04</td>\n",
       "      <td>1.220452e+03</td>\n",
       "      <td>160.520407</td>\n",
       "      <td>3030.690709</td>\n",
       "      <td>6.684949e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16265.554666</td>\n",
       "      <td>4.805380e+17</td>\n",
       "      <td>0.232355</td>\n",
       "      <td>0.362455</td>\n",
       "      <td>0.386912</td>\n",
       "      <td>1.389009e+06</td>\n",
       "      <td>1.995991e+04</td>\n",
       "      <td>3696.298209</td>\n",
       "      <td>15509.481248</td>\n",
       "      <td>3.938906e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3273.000000</td>\n",
       "      <td>2.369773e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18905.500000</td>\n",
       "      <td>1.050035e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34721.250000</td>\n",
       "      <td>1.056234e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>2.672500e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>3.182500e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50537.000000</td>\n",
       "      <td>1.079456e+18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.069380e+08</td>\n",
       "      <td>2.141379e+06</td>\n",
       "      <td>606500.000000</td>\n",
       "      <td>886115.000000</td>\n",
       "      <td>2.766520e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0            id      verified   geo_enabled  \\\n",
       "count  63264.000000  6.326400e+04  55721.000000  56860.000000   \n",
       "mean   20393.214356  7.179809e+17      0.057267      0.155575   \n",
       "std    16265.554666  4.805380e+17      0.232355      0.362455   \n",
       "min        0.000000  5.860000e+02      0.000000      0.000000   \n",
       "25%     3273.000000  2.369773e+09      0.000000      0.000000   \n",
       "50%    18905.500000  1.050035e+18      0.000000      0.000000   \n",
       "75%    34721.250000  1.056234e+18      0.000000      0.000000   \n",
       "max    50537.000000  1.079456e+18      1.000000      1.000000   \n",
       "\n",
       "       default_profile  followers_count  friends_count   listed_count  \\\n",
       "count     56166.000000     6.326400e+04   6.326400e+04   63264.000000   \n",
       "mean          0.816704     5.140114e+04   1.220452e+03     160.520407   \n",
       "std           0.386912     1.389009e+06   1.995991e+04    3696.298209   \n",
       "min           0.000000     0.000000e+00   0.000000e+00       0.000000   \n",
       "25%           1.000000     0.000000e+00   0.000000e+00       0.000000   \n",
       "50%           1.000000     2.000000e+00   3.600000e+01       0.000000   \n",
       "75%           1.000000     1.000000e+02   2.672500e+02       1.000000   \n",
       "max           1.000000     1.069380e+08   2.141379e+06  606500.000000   \n",
       "\n",
       "       favourites_count  statuses_count  \n",
       "count      63264.000000    6.326400e+04  \n",
       "mean        3030.690709    6.684949e+03  \n",
       "std        15509.481248    3.938906e+04  \n",
       "min            0.000000    0.000000e+00  \n",
       "25%            0.000000    1.100000e+01  \n",
       "50%            0.000000    4.500000e+01  \n",
       "75%          125.000000    3.182500e+02  \n",
       "max       886115.000000    2.766520e+06  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.describe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 NaN Unnamed: 0 records.\n",
      "Found 0 NaN id records.\n",
      "Found 7543 NaN bot records.\n",
      "Found 32995 NaN description records.\n",
      "Found 0 NaN probe_timestamp records.\n",
      "Found 0 NaN created_at records.\n",
      "Found 2987 NaN lang records.\n",
      "Found 11086 NaN protected records.\n",
      "Found 7543 NaN verified records.\n",
      "Found 6404 NaN geo_enabled records.\n",
      "Found 7098 NaN default_profile records.\n",
      "Found 0 NaN followers_count records.\n",
      "Found 0 NaN friends_count records.\n",
      "Found 0 NaN listed_count records.\n",
      "Found 0 NaN favourites_count records.\n",
      "Found 0 NaN statuses_count records.\n",
      "Found 0 NaN source records.\n"
     ]
    }
   ],
   "source": [
    "#Found the NaN values for each column\n",
    "for i in df.columns:\n",
    "    print(\"Found {} NaN {} records.\".format(df[i].isna().sum(), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 NaN Unnamed: 0 records.\n",
      "Found 0 NaN id records.\n",
      "Found 0 NaN bot records.\n",
      "Found 28703 NaN description records.\n",
      "Found 0 NaN probe_timestamp records.\n",
      "Found 0 NaN created_at records.\n",
      "Found 1987 NaN lang records.\n",
      "Found 3543 NaN protected records.\n",
      "Found 0 NaN verified records.\n",
      "Found 0 NaN geo_enabled records.\n",
      "Found 0 NaN default_profile records.\n",
      "Found 0 NaN followers_count records.\n",
      "Found 0 NaN friends_count records.\n",
      "Found 0 NaN listed_count records.\n",
      "Found 0 NaN favourites_count records.\n",
      "Found 0 NaN statuses_count records.\n",
      "Found 0 NaN source records.\n"
     ]
    }
   ],
   "source": [
    "#Target value is column 'bot' I dropped all the NaN bot column\n",
    "df = df.dropna(subset=['bot'])\n",
    "for i in df.columns:\n",
    "    print(\"Found {} NaN {} records.\".format(df[i].isna().sum(), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill NaN description, if no descrption is 0 otherwise 1\n",
    "df['description'] = df.description.fillna(0)\n",
    "df['has_description'] = df.loc[:, 'description'].apply(lambda x: 0 if x == 0 else 1)\n",
    "df = df.drop(['description'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if no lenguage is English then attribute is 0, 1 otherwise\n",
    "df['len_en'] = df.loc[:, 'lang'].apply(lambda x: 1 if x == 'en' else 0)\n",
    "df = df.drop(['lang'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform bot column into dummy\n",
    "df['bot'] = df.loc[:, 'bot'].apply(lambda x: 0 if x == 'human' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## 1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model only with to features that we need\n",
    "df_to_model = df[['bot', 'verified', 'geo_enabled', 'default_profile', 'has_description', 'len_en', 'followers_count', \n",
    "                  'friends_count', 'listed_count', 'favourites_count', 'statuses_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data before split: 55721\n",
      "Train size data: 44576\n",
      "Test size data: 11145\n"
     ]
    }
   ],
   "source": [
    "#Split\n",
    "df_train, df_test = p.split(df_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\"Train data before fillna with median value:\"\n",
      "\u001b[0m followers_count     0\n",
      "friends_count       0\n",
      "listed_count        0\n",
      "favourites_count    0\n",
      "statuses_count      0\n",
      "dtype: int64\n",
      "\u001b[4m\"Test data before fillna with median value:\"\n",
      "\u001b[0m followers_count     0\n",
      "friends_count       0\n",
      "listed_count        0\n",
      "favourites_count    0\n",
      "statuses_count      0\n",
      "dtype: int64\n",
      "\n",
      "\u001b[1m\u001b[92m\"Median Values to fill\" {'followers_count': 1.0, 'friends_count': 21.0, 'listed_count': 0.0, 'favourites_count': 0.0, 'statuses_count': 40.0} \u001b[0m\n",
      "\n",
      "\u001b[4m\u001b[94m\"Sanity check: Train data after fillna with median value\"\n",
      "\u001b[0m followers_count     0\n",
      "friends_count       0\n",
      "listed_count        0\n",
      "favourites_count    0\n",
      "statuses_count      0\n",
      "dtype: int64\n",
      "\u001b[4m\u001b[94m\"Sanity check: Test data after fillna with median value\"\n",
      "\u001b[0m followers_count     0\n",
      "friends_count       0\n",
      "listed_count        0\n",
      "favourites_count    0\n",
      "statuses_count      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = p.replace_missing(df_train, df_test, ['followers_count', \n",
    "                  'friends_count', 'listed_count', 'favourites_count', 'statuses_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define features and target\n",
    "labels = df_train.loc[:, df_train.columns != 'bot'].columns.values\n",
    "train_target = df_train.loc[:, 'bot']\n",
    "train_features = df_train.loc[:, df_train.columns != 'bot']\n",
    "test_target = df_test.loc[:, 'bot']\n",
    "test_features = df_test.loc[:, df_train.columns != 'bot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-772224ee6bbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                    refit='accuracy')\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mgrid_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mcv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    895\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geoenvnew\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "seed=0\n",
    "k=10\n",
    "# Decision Tree by the function\n",
    "dt = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "params = {'criterion':['entropy', 'gini'], 'max_depth':[1,3,5], 'min_samples_split':[2,5,10,20]}\n",
    "\n",
    "grid_tree = GridSearchCV(estimator=dt, param_grid=params,\n",
    "                   cv=k, return_train_score=True,\n",
    "                   scoring = ['accuracy', 'precision', 'recall'],\n",
    "                   refit='accuracy')\n",
    "\n",
    "grid_tree.fit(train_features, train_target)\n",
    "cv_results = pd.DataFrame(grid_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['param_criterion','param_max_depth', 'param_min_samples_split', \n",
    "                   'rank_test_accuracy', 'mean_test_accuracy', 'mean_test_precision',\n",
    "                   'mean_test_recall']\n",
    "results = cv_results.sort_values(by='rank_test_accuracy', ascending=True)\n",
    "results = results[columns]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "best = grid_tree.best_estimator_\n",
    "dot_data = tree.export_graphviz(best, out_file=None, feature_names=labels, class_names=True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = best.feature_importances_\n",
    "\n",
    "# Sort in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Sort the labels in a corresponding fashion\n",
    "names = [labels[i] for i in indices]\n",
    "\n",
    "# Plot\n",
    "sns.set(rc={'figure.figsize':(10, 5)})\n",
    "sns.set_style(\"white\")\n",
    "plt.figure()\n",
    "plt.title('Figure 1 - Most important feature best accuracy model, Decision Tree', fontsize=22)\n",
    "plt.ylabel('Percentage importance', fontsize=15, fontweight='bold')\n",
    "plt.xlabel('Feature', fontsize=15, fontweight='bold')\n",
    "plt.bar(range(train_features.shape[1]),importances[indices])\n",
    "plt.xticks(range(train_features.shape[1]), names, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report, plot_precision_recall_curve, precision_recall_curve\n",
    "\n",
    "#Predict the values of the train\n",
    "test_pred=best.predict(test_features)\n",
    "\n",
    "#Plot the confusion matrix\n",
    "plot_confusion_matrix(best,train_features,train_target)\n",
    "plt.title('Figure 2 - Confusion matrix best accuracy model, Decision Tree', fontsize=22)\n",
    "print(metrics.confusion_matrix(test_target, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the metrics for the Decision Tree model\n",
    "print(\"Accuracy:\\t{}\\nPrecision:\\t{}\\nRecall:\\t\\t{}\\nF1 Score:\\t{}\\n\".format(metrics.accuracy_score(test_target, test_pred),\n",
    "                                                                           metrics.precision_score(test_target, test_pred),\n",
    "                                                                           metrics.recall_score(test_target, test_pred),\n",
    "                                                                           metrics.f1_score(test_target, test_pred)\n",
    "                                                                          ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Precision Recall curve best model decision tree\n",
    "plot_precision_recall_curve(best,test_features,test_target)\n",
    "plt.title('Figure 3 - Precision Recall Curve Best Model Decision Tree', fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "params2 = {'criterion':['entropy', 'gini'], 'max_depth':[1,3,5], 'min_samples_split':[2,5,10], 'n_estimators':[100,1000,5000]}\n",
    "\n",
    "grid_rf = GridSearchCV(estimator=rf, param_grid=params2,\n",
    "                   cv=k, return_train_score=True,\n",
    "                   scoring = ['accuracy', 'precision', 'recall'],\n",
    "                   refit='accuracy')\n",
    "\n",
    "grid_rf.fit(train_features, train_target)\n",
    "cv_results_rf = pd.DataFrame(grid_rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf = cv_results_rf.sort_values(by='rank_test_accuracy', ascending=True)\n",
    "results_rf = results_rf[['param_criterion','param_max_depth', \n",
    "                                'param_min_samples_split', 'param_n_estimators', \n",
    "                                'mean_test_accuracy', 'rank_test_accuracy',\n",
    "                                'mean_test_precision', 'mean_test_recall']]\n",
    "results_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestrf = grid_rf.best_estimator_\n",
    "bestrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_rf = bestrf.feature_importances_\n",
    "\n",
    "# Sort in descending order\n",
    "indices_rf = np.argsort(importances_rf)[::-1]\n",
    "\n",
    "# Sort the labels in a corresponding fashion\n",
    "names_rf = [labels[i] for i in indices_rf]\n",
    "\n",
    "# Plot\n",
    "sns.set(rc={'figure.figsize':(10, 5)})\n",
    "sns.set_style(\"white\")\n",
    "plt.figure()\n",
    "plt.title('Figure 8 - Most important feature best accuracy model Random Forest', fontsize=22)\n",
    "plt.ylabel('Percentage importance', fontsize=15, fontweight='bold')\n",
    "plt.xlabel('Feature', fontsize=15, fontweight='bold')\n",
    "plt.bar(range(train_features.shape[1]),importances_rf[indices])\n",
    "plt.xticks(range(train_features.shape[1]), names_rf, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = bestrf.predict(test_features)\n",
    "plot_confusion_matrix(bestrf,train_features,train_target)\n",
    "plt.title('Figure 9 - Confusion Matrix Best Model of Random Forest', fontsize=22)\n",
    "print(metrics.confusion_matrix(test_target, test_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete preicision recall curve for random forst\n",
    "plot_precision_recall_curve(bestrf,test_features,test_target)\n",
    "plt.title('Figure 10 - Precision Recall Curve Random Forest', fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naive Bayes\n",
    "#### Challenges:\n",
    "Scikit Learn's Naive Bayes Model assumes same type of distribution for all features. However, there are multiple types of features in our dataset, including binomial variables(verified, geoenabled, default_profile, has_description, len_en) and continuous variables(followers_count, friends_count, listed_count, favourites_count, statuses_count). \n",
    "\n",
    "To proceed, we decide to assume multinomial distribution for our features for two reasons. First, it is reasonable to transform continuous variables into categorical variables through discretization. Second,binomial distribution is simply a special case of multinomial distribution. \n",
    "\n",
    "#### Transform continuous variables to categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 10, 100, 1000, 10000, 106938028]\n",
      "[0, 10, 100, 1000, 10000, 2141379]\n",
      "[0, 10, 100, 1000, 10000, 224105]\n",
      "[0, 10, 100, 1000, 10000, 886115]\n",
      "[0, 10, 100, 1000, 10000, 2766520]\n",
      "[0, 10, 100, 1000, 10000, 105043889]\n",
      "[0, 10, 100, 1000, 10000, 1250468]\n",
      "[0, 10, 100, 1000, 10000, 606500]\n",
      "[0, 10, 100, 1000, 10000, 577666]\n",
      "[0, 10, 100, 1000, 10000, 1101318]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bot</th>\n",
       "      <th>verified</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>has_description</th>\n",
       "      <th>len_en</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>cat_followers_count</th>\n",
       "      <th>cat_friends_count</th>\n",
       "      <th>cat_listed_count</th>\n",
       "      <th>cat_favourites_count</th>\n",
       "      <th>cat_statuses_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11658</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "      <td>473</td>\n",
       "      <td>488</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10293</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47061</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>752</td>\n",
       "      <td>765</td>\n",
       "      <td>72</td>\n",
       "      <td>10498</td>\n",
       "      <td>41776</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53260</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1004</td>\n",
       "      <td>1595</td>\n",
       "      <td>46</td>\n",
       "      <td>10804</td>\n",
       "      <td>32873</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21949</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bot  verified  geo_enabled  default_profile  has_description  len_en  \\\n",
       "11658    1       0.0          0.0              1.0                1       1   \n",
       "10293    1       0.0          0.0              1.0                0       0   \n",
       "47061    0       0.0          1.0              0.0                1       1   \n",
       "53260    0       0.0          1.0              0.0                1       1   \n",
       "21949    1       0.0          0.0              1.0                0       1   \n",
       "\n",
       "       followers_count  friends_count  listed_count  favourites_count  \\\n",
       "11658              320            480             0               473   \n",
       "10293                0             21             0                 0   \n",
       "47061              752            765            72             10498   \n",
       "53260             1004           1595            46             10804   \n",
       "21949                0              0             0                 0   \n",
       "\n",
       "       statuses_count cat_followers_count cat_friends_count cat_listed_count  \\\n",
       "11658             488                   3                 3                1   \n",
       "10293               5                   1                 2                1   \n",
       "47061           41776                   3                 3                2   \n",
       "53260           32873                   4                 4                2   \n",
       "21949              45                   1                 1                1   \n",
       "\n",
       "      cat_favourites_count cat_statuses_count  \n",
       "11658                    3                  3  \n",
       "10293                    1                  1  \n",
       "47061                    5                  5  \n",
       "53260                    5                  5  \n",
       "21949                    1                  2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are patitioning each continuous variables into 5 bins (Hey Maca and Rukhshan, I think we should take care of outliers earlier in the dataset)\n",
    "continuous_var = [\"followers_count\",\"friends_count\",\"listed_count\",\"favourites_count\",\"statuses_count\"]\n",
    "nb_train = df_train.copy()\n",
    "nb_test = df_test.copy()\n",
    "datasets = [nb_train, nb_test]\n",
    "bin_labels_5 = [1,2,3,4,5] #five levels\n",
    "        \n",
    "for df_now in datasets:\n",
    "    for variable in continuous_var :\n",
    "        new_name = \"cat_\"+ variable\n",
    "        cut_bins = [0,10,100,1000,10000, df_now[variable].max()]\n",
    "        print(cut_bins)\n",
    "        df_now[new_name] = pd.Series(pd.cut(df_now[variable], bins=cut_bins, labels=bin_labels_5, include_lowest=True))\n",
    "        \n",
    "nb_train.head()\n",
    "#nb_train[\"followers_count\"].quantile(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the needed columns\n",
    "nb_model_train= nb_train[['bot', 'verified', 'geo_enabled', 'default_profile', 'has_description', 'len_en', 'cat_followers_count', \n",
    "                  'cat_friends_count', 'cat_listed_count', 'cat_favourites_count', 'cat_statuses_count']]\n",
    "nb_model_test = nb_test[['bot', 'verified', 'geo_enabled', 'default_profile', 'has_description', 'len_en', 'cat_followers_count', \n",
    "                  'cat_friends_count', 'cat_listed_count', 'cat_favourites_count', 'cat_statuses_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all variables are categorical/binomial now, we don't need to normalize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting features and target\n",
    "labels = nb_model_train.loc[:, nb_model_train.columns != 'bot'].columns.values\n",
    "nb_train_target = nb_model_train.loc[:, 'bot']\n",
    "nb_train_features = nb_model_train.loc[:, nb_model_train.columns != 'bot']\n",
    "nb_test_target = nb_model_test .loc[:, 'bot']\n",
    "nb_test_features = nb_model_test .loc[:, nb_model_test .columns != 'bot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                   1.0],\n",
       "                         'class_prior': [None, [0.1, 0.9], [0.2, 0.8]],\n",
       "                         'fit_prior': [True, False]},\n",
       "             refit='accuracy', scoring=['accuracy', 'precision', 'recall'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Model using randomized search\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "#params = {'class_prior': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,None]}\n",
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "params= {'alpha': alphas, 'fit_prior' : [True, False], 'class_prior' : [None, [.1,.9],[.2, .8]]}\n",
    "#random_search = RandomizedSearchCV(estimator = naive_bayes, param_distributions= params, scoring='accuracy',n_iter=10,cv=10,random_state=0)\n",
    "grid_search = GridSearchCV(estimator = naive_bayes, param_grid = params, scoring = [\"accuracy\", \"precision\",\"recall\"],cv=10, refit='accuracy')\n",
    "# train the model\n",
    "nb_model = random_search.fit(nb_train_features, nb_train_target)\n",
    "grid_search.fit(nb_train_features, nb_train_target)\n",
    "# scores\n",
    "#random_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_alpha', 'param_class_prior', 'param_fit_prior', 'params',\n",
       "       'split0_test_accuracy', 'split1_test_accuracy', 'split2_test_accuracy',\n",
       "       'split3_test_accuracy', 'split4_test_accuracy', 'split5_test_accuracy',\n",
       "       'split6_test_accuracy', 'split7_test_accuracy', 'split8_test_accuracy',\n",
       "       'split9_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy',\n",
       "       'rank_test_accuracy', 'split0_test_precision', 'split1_test_precision',\n",
       "       'split2_test_precision', 'split3_test_precision',\n",
       "       'split4_test_precision', 'split5_test_precision',\n",
       "       'split6_test_precision', 'split7_test_precision',\n",
       "       'split8_test_precision', 'split9_test_precision', 'mean_test_precision',\n",
       "       'std_test_precision', 'rank_test_precision', 'split0_test_recall',\n",
       "       'split1_test_recall', 'split2_test_recall', 'split3_test_recall',\n",
       "       'split4_test_recall', 'split5_test_recall', 'split6_test_recall',\n",
       "       'split7_test_recall', 'split8_test_recall', 'split9_test_recall',\n",
       "       'mean_test_recall', 'std_test_recall', 'rank_test_recall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_class_prior</th>\n",
       "      <th>param_fit_prior</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930523</td>\n",
       "      <td>0.940457</td>\n",
       "      <td>0.973461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930523</td>\n",
       "      <td>0.940457</td>\n",
       "      <td>0.973461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930523</td>\n",
       "      <td>0.940457</td>\n",
       "      <td>0.973461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.7</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930523</td>\n",
       "      <td>0.940457</td>\n",
       "      <td>0.973461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930523</td>\n",
       "      <td>0.940457</td>\n",
       "      <td>0.973461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_alpha param_class_prior param_fit_prior  rank_test_accuracy  \\\n",
       "0          0.1              None            True                   1   \n",
       "54           1              None            True                   1   \n",
       "24         0.5              None            True                   1   \n",
       "36         0.7              None            True                   1   \n",
       "6          0.2              None            True                   1   \n",
       "\n",
       "    mean_test_accuracy  mean_test_precision  mean_test_recall  \n",
       "0             0.930523             0.940457          0.973461  \n",
       "54            0.930523             0.940457          0.973461  \n",
       "24            0.930523             0.940457          0.973461  \n",
       "36            0.930523             0.940457          0.973461  \n",
       "6             0.930523             0.940457          0.973461  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "columns = ['param_alpha','param_class_prior','param_fit_prior' , \n",
    "                   'rank_test_accuracy', 'mean_test_accuracy','mean_test_precision','mean_test_recall']\n",
    "results = cv_results.sort_values(by='rank_test_accuracy', ascending=True)\n",
    "results = results[columns]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9305231898889673\n",
      "{'alpha': 0.1, 'class_prior': None, 'fit_prior': True}\n",
      "MultinomialNB(alpha=0.1)\n"
     ]
    }
   ],
   "source": [
    "# Examine the best model\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.9329744279946164\n",
      "Precision:\t0.9415584415584416\n",
      "Recall:\t\t0.9753733895792954\n",
      "F1 Score:\t0.9581676653413227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Use the best model to predict test data\n",
    "bestnb = grid_search.best_estimator_\n",
    "test_pred_nb = bestnb.predict(nb_test_features)\n",
    "metrics.confusion_matrix(nb_test_target, test_pred_nb)\n",
    "print(\"Accuracy:\\t{}\\nPrecision:\\t{}\\nRecall:\\t\\t{}\\nF1 Score:\\t{}\\n\".format(metrics.accuracy_score(nb_test_target, test_pred_nb),\n",
    "                                                                           metrics.precision_score(nb_test_target, test_pred_nb),\n",
    "                                                                           metrics.recall_score(nb_test_target, test_pred_nb),\n",
    "                                                                           metrics.f1_score(nb_test_target, test_pred_nb)\n",
    "                                                                          ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geoenvnew]",
   "language": "python",
   "name": "conda-env-geoenvnew-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
