{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "We have two dataset:\n",
    "* One to train our models (see data consolidation) called 'verified', this dataset compiles different sources of labeled tweets account as human or bot.\n",
    "* Other dataset to test our models, this dataset has tweets account that posted information about COVID. This dataset will be called COVID.\n",
    "\n",
    "On this notebook we will clean the data and get a final version of this datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pipeline as p\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Verified\" Dataset cleaning\n",
    "We will explore all the columns of this dataset and after all the cleaning process we wil hace a new cvs file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the complete dataset\n",
    "df = pd.read_csv(\"C:/Users/Maca/Documents/project_ml/Project-Machine-Learning-CAPP/data_consolidation/consolidated_version2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print some rows to see the data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns of the dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get some stats about the columns\n",
    "p.describe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Found the NaN values for each column\n",
    "for i in df.columns:\n",
    "    print(\"Found {} NaN {} records.\".format(df[i].isna().sum(), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our target value is column 'bot', we dropped all the NaN bot column\n",
    "df = df.dropna(subset=['bot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target - Bot column\n",
    "Column bot is our target column.\n",
    "For that reason we need to transfrom into a dummy column. If 'bot' column has the value bot we will assign a number 1 and 0 otherwise (value human)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform bot column into dummy\n",
    "df['bot'] = df.loc[:, 'bot'].apply(lambda x: 0 if x == 'human' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lenguage Description Column\n",
    "Column lenguage is one of our categorical features. If the lenguage of the tweeter account is english we will assign a number 1 and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if no lenguage is English then attribute is 0, 1 otherwise\n",
    "df['len_en'] = df.loc[:, 'lang'].apply(lambda x: 1 if x == 'en' else 0)\n",
    "df = df.drop(['lang'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bio Description Column\n",
    "Column description is one of our categorical features. If the bio has a description on the tweeter account we will assign a number 1 and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill NaN description, if no descrption is 0 otherwise 1\n",
    "df['description'] = df.description.fillna(0)\n",
    "df['has_description'] = df.loc[:, 'description'].apply(lambda x: 0 if x == 0 else 1)\n",
    "df = df.drop(['description'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally select only the features for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model only with to features that we need\n",
    "verified= df[['bot', 'verified', 'geo_enabled', 'default_profile', 'has_description', 'len_en', 'followers_count', \n",
    "                  'friends_count', 'listed_count', 'favourites_count', 'statuses_count']]\n",
    "columns = {'followers_count':'followers','friends_count': 'friends', 'favourites_count': 'likes', 'statuses_count': 'tweets'}\n",
    "verified = verified.rename(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified.to_csv(r'C:\\Users\\Maca\\Documents\\project_ml\\Project-Machine-Learning-CAPP\\Data-Cleaning\\verified.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"COVID\" Dataset cleaning\n",
    "We will explore all the columns of this dataset and after all the cleaning process we wil hace a new cvs file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(r'C:\\Users\\Maca\\Documents\\project_ml\\Project-Machine-Learning-CAPP\\covid_user_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and target of COVID dataset\n",
    "The idea behind this dataset is to test our trained model. This dataset doesn't contain the target column labeled as 'bot' or 'human' but it has almost all the features of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_filtered = df2[['bio', 'followers', 'following', 'location', 'tweets','likes', 'verified']]\n",
    "columns2 = {'following': 'friends', 'location': 'geo_enabled'}\n",
    "covid_filtered = covid_filtered.rename(columns=columns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the NaN values\n",
    "for i in covid_filtered.columns:\n",
    "    print(\"Found {} NaN {} records.\".format(covid_filtered[i].isna().sum(), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bio Description Column\n",
    "Column description is one of our categorical features. If the bio has a description on the tweeter account we will assign a number 1 and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill NaN description, if no descrption is 0 otherwise 1\n",
    "covid_filtered['has_description '] = covid_filtered.has_description.fillna(0)\n",
    "covid_filtered['has_description'] = covid_filtered.loc[:, 'has_description '].apply(lambda x: 0 if x == 0 else 1)\n",
    "covid_filtered = covid_filtered.drop(['bio'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geolocalization Description Column\n",
    "Column geolocalization is one of our categorical features. If the geolocalization is enabled we will assign a number 1 and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill NaN geolocalization, if no geolocalization is 0 otherwise 1\n",
    "covid_filtered['geo_enabled'] = covid_filtered.geo_enabled.fillna(0)\n",
    "covid_filtered['geo_enabled'] = covid_filtered.loc[:, 'has_description '].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical column: Verified records\n",
    "As we have 26 null values on the verified column, we will remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_filtered = covid_filtered[covid_filtered['verified'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous columns: Replace NaNs with median value of the dataset\n",
    "Our continuous columns are: followers, friends, tweets and likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = ['followers', 'friends', 'tweets', 'likes']\n",
    "d = {}\n",
    "print('\\033[4m\"Data before fillna with median value:\"\\n\\x1b[0m', covid_filtered[continuous].isna().sum())\n",
    "for i in continuous:\n",
    "    d[i] = covid_filtered[i].median()\n",
    "print('\\n\\033[1m\\33[92m\"Median Values to fill\"', d, '\\x1b[0m\\n')\n",
    "covid_filtered = covid_filtered.fillna(value=d)\n",
    "print('\\033[4m\\033[94m\"Sanity check: Data after fillna with median value\"\\n\\x1b[0m', covid_filtered[continuous].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the NaN values\n",
    "for i in covid_filtered.columns:\n",
    "    print(\"Found {} NaN {} records.\".format(covid_filtered[i].isna().sum(), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_filtered.to_csv(r'C:\\Users\\Maca\\Documents\\project_ml\\Project-Machine-Learning-CAPP\\Data-Cleaning\\COVID_tweet.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
